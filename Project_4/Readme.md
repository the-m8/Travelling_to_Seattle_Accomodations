# Capstone Project: Segmentation Report for Arvato/Bertelsman

With the Disaster Response Pipeline, messages regarding disasters gets classified by a machine learning pipeline.

## Table of contents
1. [Installation](#installation)
2. [Project Motivation](#motivation)
3. [File Descriptions](#files)
4. [Instruction](#instructions)
5. [Licensing, Authors, and Acknowledgements](#licensing)

## Installation <a name="installation"></a>

This project uses Pandas, Numpy, Seaborn, Matplotlib and some sklearn libraries. The code should run with no issues using Python versions 3.*.

## Project Motivation<a name="motivation"></a>

This is my final project in the Udacity Data Science Nanodegree. To proof my Data Science skills and to earn the Data Science Nanodegree certificate, I will provide a customer segmentation report for Bertelsmann/arvato emphasizing the attributes of the customers - especially with regards to the general population in Germany. Furthermore, I will analyze the dataset with Machine Learning Models to find out what kind of people attributes will likely lead to a positive response regarding customer acquisition. 

## File Descriptions <a name="files"></a>

This projects contains csv files of messages and categories that gets cleaned and tranformed in an ETL Pipeline. The pipeline preparation in Jupyther Notebook as well as the final ETL python pipeline can be found in the folder "data". Second, a Machine Learning pipeline trains and tests on the dataset to select the respective categories after a message input. This machine learning pipeline preparation as well as the final ML python pipeline and the saved model can be found in the folder "model". Third, a webpage with an application on Disaster Response is provided with the past data and created model underlying. The python code for the webapp is provided in the folder "app".

## Instruction<a name="instructions"></a>



## Results <a name="results"></a>




## Licensing, Authors, Acknowledgements<a name="licensing"></a>

Credits to [appen](https://appen.com/) for the data. 
